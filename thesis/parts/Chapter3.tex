\section{Обзор существующих решений задачи мостов Шрёдингера}
\label{sec:Chapter3} \index{Chapter3}

Для более полного анализа поставленной проблемы, далее рассматриваются существующие методы решения задачи эмпирических мостов Шрёдингера.

\subsection{Data Driven Schrödinger Bridge}
Подход, предложенный в статье \cite{pavon-empiric-fortret}, является адаптацией алгоритма \ref{alg:fortret} к эмпирической постановке. Данный метод основан на том факте факте, что шаги 4 и 6 \ref{alg:fortret}:
\begin{equation*}
    \begin{split}
    \hat{\phi}^{(i)}_0(x) := \frac{\pi_0(x)}{\phi^{(i)}_0(x)}, \\
    \phi^{(i)}_T(y) := \frac{\pi_T(y)}{\hat{\phi}^{(i)}_T(y)}
    \end{split}
\end{equation*}
могут быть эквивалентно сформулированы как проблема минимизации кросс-энтропии в пространстве распределений $\mathcal{H}$:
\begin{equation*}
    \begin{split}
        \hat{\phi}^{(i)}_0(x) = \arg \sup_{\phi_0(x) \in \mathcal{H}} \mathbb{E}_{\pi_0(x)} \left[ \ln \hat{\phi}_0(x) \phi^{(i)}_0(x) \right],\\
        \phi^{(i)}_T(y) = \arg \sup_{\phi_T(y) \in \mathcal{H}} \mathbb{E}{\pi_T(y)} \left[ \ln \phi_T(y) \hat{\phi}^{(i)}_T(y) \right].
    \end{split}
\end{equation*}

Далее, внедряя шаги 5 и 7 алгоритма \ref{alg:fortret} с помощью лагранжиана и параметризуя потенциалы с помощью смеси гауссиан, получают следующие два шага нового алгоритма:
\begin{equation*}
    \beta^{*}_i = \arg \max{\hat{\beta}} \frac{1}{M} \sum_{s} \ln \hat{\phi}_0(x_s; \hat{\beta}) \phi^{(i)}_0(x_s) - \int \hat{\phi}_0(x; \hat{\beta}) \phi^{(i)}_0(x) dx, \quad x_s \sim \pi_0(x),
\end{equation*}
и
\begin{equation*}
    \beta^{*}_i = \arg \max{\beta} \frac{1}{N} \sum_{s} \ln \phi_T(y_s; \beta) \hat{\phi}^{(i)}_T(y_s) - \int \phi_T(y; \beta) \hat{\phi}^{(i)}_T(y) dy, \quad y_s \sim \pi_T(y).
\end{equation*}

Далее декомпозируются ограничения введенные лагранжианом и оцениваются с помощью метода Монте Карло и выборки по значимости, и получают финальные оптимизационные задачи. Из-за проклятия размерности метода выборки по значимости, предложенный метод не масштабируется до данных с большой размерностью.

\subsection{Light Schrödinger Bridge}
Данный метод предложенный в \cite{lsb} решает задачу мостов Шрёдингера в статической формулировке \ref{static}, декомпозируя совместное распределение с помощью потенциалов:
\begin{equation*}
    \pi_{\theta}(x_0, x_1) = \pi_0(x) p^{\mathbb{W}^\gamma}(y|x) = \pi_0(x) \frac{p^{\mathbb{W}^\gamma}(y|x) \phi_T(y)}{\hat{\phi}_0(x)}.
\end{equation*}

Аналогично с предыдущим методом авторы параметризуют потенциалы с помощью смеси гауссиан. Далее авторы замечают, что данная декомпозиция позволяет сформулировать целевую функцию, минимизация которой эквивалентна минимизации дивергенции Кульбака-Лейблера:
\begin{equation*}
    L(\theta) = \int_{\mathbb{R}^D} \log \hat{\phi}_0(x) \pi_0(x)dx - \int_{\mathbb{R}^D} \log \phi_T(y) \pi_T(y) dy.
\end{equation*}

Напрямую решая задачу мостов Шрёдингера (без IPF), авторам удалось значительно ускорить обучения моделей, однако авторы комментируют, что такой метод не предназначен для работы с данными большой размерности.

\subsection{Diffusion Schrödinger Bridge}
Данный метод предложен Валентином Де Бортоли в статье \cite{dsb}. Автор рассматривает динамическую постановку задачи \ref{dyn} в дискретном виде, то есть вместо меры пути используют совместное распределение в точках стохастического процесса:
\begin{equation*}
    q^*(x_0, \ldots, x_T) = \arg \min_{q \in \mathcal{D}(\pi_0, \pi_T)} D_{KL}\left(q(x_0, \ldots, x_T) || p^{\mathbb{W}^\gamma}(x_0, \ldots, x_T)\right).
\end{equation*} 

Авторы доказывают, что формулировка задачи мостов Шрёдингера через совместные вероятности эквивалентна динамической постановке мостов Шрёдингера, у которой ассоциированный стохастический процесс дискретизирован с помощью метода Эйлера–Маруямы. Используя данный факт, авторы \cite{dsb} применяют алгоритм IPF, адаптированный к дискретной формулировке, для решения задачи мостов Шрёдингера. В результате основываясь на факте, что винеровский процесс является марковским, авторы формулируют минимизационные задачи IPF следующим образом:

\begin{equation}
    \begin{split}
        p^{i+1}(x_{0:T}) = \pi_0(x_0) \prod_{t=0}^{T-1} \left( \frac{q_{t|t+1}^i (x_t | x_{t+1}) q_{t+1}^i (x_{t+1})}{q_t^i (x_t)} \right),
        \\
        q^i(x_{0:T}) = \pi_T(x_T) \prod_{t=0}^{T-1} \left( \frac{p_{t+1|t}^i (x_{t+1} | x_t) p_t^i (x_t)}{p_{t+1}^i (x_{t+1})} \right).
    \end{split}
    \label{eq:dsb-prop2}
\end{equation}

Так как такую динамику смоделировать невозможно, условные вероятности $p_{t+1|t}^i(x_{t+1} | x_t)$ и $q_{t|t+1}^i (x_t | x_{t+1})$ представляют с помощью нормального распределения:
\begin{equation*}
    \begin{split}
        p_{t+1|t}^i (x_{t+1} | x_t) p_t^i (x_t) =  \mathcal{N}\left(x_{t+1};x_{t} + \gamma_{t+1}f^i_t(x_t), 2\gamma_{t+1}\mathbb{I}\right)
        \\
        q_{t|t+1}^i (x_t | x_{t+1}) = \mathcal{N}\left(x_{t};x_{t+1} + \gamma_{t}b^i_{t+1}(x_{t+1}), 2\gamma_{t}\mathbb{I}\right).
    \end{split}
\end{equation*}

Далее аппроксимировав с помощью ряда Тейлора, для \ref{eq:dsb-prop2} авторы получают:
\begin{equation*}
    \begin{split}
        p^{i+1}_{t+1|t}(x_{t+1} | x_t) \approx \mathcal{N}(x_{t+1}; x_t + \gamma_{t+1} f^{i+1}_t(x_t), 2 \gamma_{t+1} I), \\
        q^i_{t|t+1}(x_t | x_{t+1}) \approx \mathcal{N}(x_t; x_{t+1} + \gamma_{t+1} b^i_{t+1}(x_{t+1}), 2 \gamma_{t+1} I),        
    \end{split}
\end{equation*}
где
\begin{equation*}
    \begin{split}
        f^{i+1}_t(x_t) = -b^i_{t+1}(x_t) + 2 \nabla \log q^i_t(x_t), \\
        b^i_{t+1}(x_{t+1}) = -f^i_t(x_{t+1}) + 2 \nabla \log p^i_{t+1}(x_{t+1}).
    \end{split}
\end{equation*}

Затем логарифмы градиентов могут быть аппроксимированы с использованием score matching методов. Однако авторы, из соображений затрат памяти и вычислительной сложности аппроксимируют, среднее нормальных распределений \ref{eq:dsb-prop2}, то есть функции дрейфа ассоциированных стохастических процессов.

Благодаря применению задачи мостов Шрёдингера, авторам удалось сократить требуемое число диффузионных шагов в сравнении с score-based моделями. Так, например, для задач генерации изображений CelebA и MNIST для score-based моделей потребовалось 100 диффузионных шагов, а для предложенного метода \cite{dsb} 12.

\subsection{Iterative Proportional Maximum Likelihood (IPML)}
В работе \cite{mle-sb} авторы преобразуют алгоритм IPF в виде задачи максимума правдоподобия. Аналогично ранее описанной работе в данном методе используется тот факт, что мера пути в динамической постановке задачи мостов Шрёдингера, может быть параметризована с помощью функции сноса соответствующего стохастического дифференциального уравнения. Однако в место того, чтобы оценивать функцию сноса с помощью score matching подхода, авторы данного метода оценивают, используя гауссовские процессы.

Также, в отличии от метода \cite{pavon-empiric-fortret}, где оценка маргинальных распределений находится с помощью метода максимума правдоподобия, авторы данной работы находят оценку условного распределения, то есть смещения. В такой постановке не требуется оценивать интеграл с помощью метода Монте Карло, что позволяет работать с данными большой размерности. Однако не смотря на это, для отображения элементов из одного набора данных в другой, моделирует стохастический процесс.

\subsection{Unpaired Neural Schrödinger Bridge}
Наиболее близкий метод к предложенному в данной работе является подход описанный в статье \cite{cycle-sb}. Авторы рассматривают динамическую задачу мостов Шрёдингера и аналогично предыдущим методам параметризуют условное распределение $q(x_{t+1}|x_t)$. Однако, в отличии от них данный метод не использует IPF для обучения, что сильно упрощает оптимизационную задачу. 

Авторы выдоят следующую целевую функцию:
\begin{equation*}
    \begin{split}
        \min_{q} \mathcal{L}_{SB}(q, t) := \mathbb{E}_{q(x_{t_i}, x_T)} \left[ \|x_{t_i} - x_1\|^2 \right] - 2\tau(1 - t_i) H(q(x_{t_i}, x_T)) \\
        \text{такое, что} \quad \mathcal{L}_{Adv}(\phi_i; t_i) := D_{KL}(q(x_T) \| \pi_T(x_T)) = 0,
    \end{split}
\end{equation*}
где дополнительное условие рассматривается как регуляризация и минимизируется с помощью состязательного обучения. Далее доказывают, что оптимизация такой целевой функции находит решения задачи моста Шрёдингера.

Таким образом, несмотря на введение состязательного обучения, данный метод не решает проблему моделирования стохастического процесса.

\newpage
